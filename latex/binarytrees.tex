\chapter{Binary Trees}
\chaplabel{binarytrees}

This chapter introduces one of the most fundamental structures in computer
science: binary trees.  There are lots of ways of defining binary trees.
Mathematically, a binary tree is a connected undirected finite graph with
no cycles, and no vertex of degree greater than three.

For most computer science applications, binary trees are \emph{rooted}: A
special node, #r#, of degree at most two is called the \emph{root} of the tree.  For every node,
$#u#\neq #r#$, the second node on the path from #u# to #r# is called the
\emph{parent} of #u#.  Each of the other nodes adjacent to #u#
is called a \emph{child} of #u#. Most of the binary trees we are interested
in are \emph{ordered}, so we distinguish between the \emph{left child}
and \emph{right child} of #u#.

In illustrations, binary trees are usually drawn from the root
downward, with the root at the top of the drawing and the left and right
children respectively given by left and right positions in the drawing
(\figref{bintree-orientation}).  A binary tree with nine nodes is drawn
this way in \figref{binary-tree}.a.

\begin{figure}
  \begin{center}
    \includegraphics{figs/bintree-traverse-1} 
  \end{center}
  \caption{The parent, left child, and right child of the node #u#
    in a #BinaryTree#.}
  \figlabel{bintree-orientation}
\end{figure}


\begin{figure}
  \begin{center}
    \begin{tabular}{ccc}
      \includegraphics{figs/bintree-1} &
      \includegraphics{figs/bintree-2} \\
      (a) & (b)
    \end{tabular}
  \end{center}
  \caption{A binary tree with (a)~nine real nodes and (b)~ten external nodes.}
  \figlabel{binary-tree}
\end{figure}

Binary trees are so important that a terminology has developed around them:
The \emph{depth} of a node, #u#, in a binary tree is the length of the
path from #u# to the root of the tree.   If a node, #w#, is on the path
from #u# to #r# then #w# is called an \emph{ancestor} of #u# and #u#
a \emph{descendant} of #w#.  The \emph{subtree} of a node, #u#, is the
binary tree that is rooted at #u# and contains all of #u#'s descendants.
The \emph{height} of a node, #u#, is the length of the longest path from
#u# to one of its descendants.  The height of a tree is the height of its root.
A node, #u#, is a \emph{leaf} if it has no children.

We sometimes think of the tree as being augmented with \emph{external
nodes}. Any node that does not have a left child has an external node
as its left child and any node that does not have a right child has an
external node as its right child (see \figref{binary-tree}.b).  It is
easy to verify, by induction, that a binary tree having $#n#\ge 1$
real nodes has $#n#+1$ external nodes.


\section{#BinaryTree#: A Basic Binary Tree}

The simplest way to represent a node, #u#, in a binary tree is
to store the (at most three) neighbours of #u# explicitly:
\javaimport{ods/BinaryTree.BTNode<Node}
\cppimport{ods/BinaryTree.BTNode}
When one of these three neighbours is not present, we set it to #nil#.
In this way, external nodes in the tree as well as the parent of the
root correspond to the value #nil#.

The binary tree itself can then be represented by a
\javaonly{reference}\cpponly{pointer} to its root node, #r#:
\codeimport{ods/BinaryTree.r}

We can compute the depth of a node, #u#, in a binary tree by counting
the number of steps on the path from #u# to the root:
\codeimport{ods/BinaryTree.depth(u)}


\subsection{Recursive Algorithms}

It is very easy to compute facts about binary trees using recursive algorithms. For example, to compute the size of (number of nodes in)
a binary tree rooted at node #u#, we recursively compute the sizes of
the two subtrees rooted at the children of #u#, sum these sizes, and add one:

\codeimport{ods/BinaryTree.size(u)}

To compute the height of a node #u# we can compute the height of #u#'s
two subtrees, take the maximum, and add one:

\codeimport{ods/BinaryTree.height(u)}

\subsection{Traversing Binary Trees}
\seclabel{bintree:traversal}

The two algorithms from the previous section use recursion to visit all
the nodes in a binary tree.  Each of them visits the nodes of the binary
tree in the same order as the following code:
\codeimport{ods/BinaryTree.traverse(u)}

Using recursion this way produces very short, simple code, but can
be problematic.  The maximum depth of the recursion is given by the
maximum depth of a node in the binary tree, i.e., the tree's height.
If the height of the tree is very large, then this could very well use
more stack space than is available, causing a crash.  

Luckily, traversing a binary tree can be done without recursion. This
is done using an algorithm that uses where it came from
to decide where it will go next.  See \figref{bintree-traverse}.
If we arrive at a node #u# from #u.parent#, then the next thing to do
is to visit #u.left#.  If we arrive at #u# from #u.left#, then the next
thing to do is to visit #u.right#.  If we arrive at #u# from #u.right#,
then we are done visiting #u#'s subtree, so we return to #u.parent#.
The following code implements this idea, with code included for handling
the cases where any of #u.left#, #u.right#, or #u.parent# is #nil#:
\codeimport{ods/BinaryTree.traverse2()}

\begin{figure}
  \begin{center}
    \begin{tabular}{cc}
      \includegraphics{figs/bintree-traverse-2}
      \includegraphics{figs/bintree-3}
    \end{tabular}
  \end{center}
  \caption{The three cases that occur at node #u# when traversing a binary tree non-recursively, and the resulting traversal of the tree.}
  \figlabel{bintree-traverse}
\end{figure}

The same things that can be computed with recursive algorithms can
also be done this way. For example, to compute the size of the tree we
keep a counter, #n#, and increment #n# whenever visiting a node for the
first time:
\codeimport{ods/BinaryTree.size2()}

In some implementations of binary trees, the #parent# field is not used.
When this is the case, a non-recursive implementation is still possible,
but the implementation has to use a #List# (or #Stack#) to keep track
of the path from the current node to the root.

A special kind of traversal that does not fit the pattern of the above
functions is the \emph{breadth-first traversal}.  In a breadth-first
traversal, the nodes are visited level-by-level starting at the root
and working our way down, visiting the nodes at each level from left
to right.  This is similar to the way we would read a page of English
text. (See \figref{bintree-bfs}.)  This is implemented using a queue, #q#,
that initially contains only the root, #r#.  At each step, we extract
the next node, #u#, from #q#, process #u# and add #u.left# and #u.right#
(if they are non-#nil#) to #q#:
\codeimport{ods/BinaryTree.bfTraverse()}

\begin{figure}
  \begin{center}
    \includegraphics{figs/bintree-4}
  \end{center}
  \caption{During a breadth-first traversal, the nodes of a binary tree
  are visited
level-by-level, and left-to-right within each level.}
  \figlabel{bintree-bfs}
\end{figure}





\section{#BinarySearchTree#: An Unbalanced Binary Search Tree}
\seclabel{binarysearchtree}

A #BinarySearchTree# is a special kind of binary tree in which each node, #u#,
also stores a data value, #u.x#, from some total order.  The data values in
a binary search tree obey the \emph{binary search tree property}:  For
a node, #u#, every data value stored in the subtree rooted at #u.left#
is less than #u.x# and every data value stored in the subtree rooted at
#u.right# is greater than #u.x#.  An example of a #BinarySearchTree# is shown in \figref{bst}.

\begin{figure}
  \begin{center}
    \includegraphics{figs/bst-example}
    %\includegraphics{figs/binary-tree-4}
  \end{center}
  \caption{A binary search tree.}
  \figlabel{bst}
\end{figure}


\subsection{Searching}

The binary search tree property is extremely useful because it allows
us to quickly locate a value, #x#, in a binary search tree.  To do this we start
searching for #x# at the root, #r#.  When examining a node, #u#, there
are three cases:
\begin{enumerate}
\item If $#x#< #u.x#$ then the search proceeds to #u.left#;
\item If $#x#> #u.x#$ then the search proceeds to #u.right#;
\item If $#x#= #u.x#$ then we have found the node #u# containing #x#.
\end{enumerate}
The search terminates when Case~3 occurs or when #u=nil#.  In the
former case, we found #x#.  In the latter case, we conclude that #x#
is not in the binary search tree.
\codeimport{ods/BinarySearchTree.findEQ(x)}

Two examples of searches in a binary search tree are shown in
\figref{bst-search}.  As the second example shows, even if we don't find #x#
in the tree, we still gain some valuable information.  If we look at
the last node, #u#, at which Case~1 occurred, we see that #u.x# is the smallest
value in the tree that is greater than #x#.  Similarly, the last node
at which Case~2 occurred contains the largest value in the tree that is
less than #x#.  Therefore, by keeping track of the last node, #z#,
at which Case~1 occurs, a #BinarySearchTree# can implement the #find(x)#
operation that returns the smallest value stored in the tree that is
greater than or equal to #x#:
\codeimport{ods/BinarySearchTree.find(x)}

\begin{figure}
  \begin{center}
    \begin{tabular}{cc}
    \includegraphics{figs/bst-example-2} &
    \includegraphics{figs/bst-example-3} \\
    (a) & (b)
    \end{tabular}
  \end{center}
  \caption{An example of (a)~a successful search (for $6$) and (b)~an unsuccessful search (for $10$) in a binary search tree.}
  \figlabel{bst-search}
\end{figure}


\subsection{Inserting}

To add a new value, #x#, to a #BinarySearchTree#, we first search for
#x#. If we find it, then there is no need to insert it.  Otherwise,
we store #x# at a leaf child of the last node, #p#, encountered during the
search for #x#. Whether the new node is the left or right child of #p# depends on the result of comparing #x# and #p.x#.
\codeimport{ods/BinarySearchTree.add(x)}
\codeimport{ods/BinarySearchTree.findLast(x)}
\codeimport{ods/BinarySearchTree.addChild(p,u)}
An example is shown in \figref{bst-insert}. The most time-consuming
part of this process is the initial search for #x#, which takes time
proportional to the height of the newly added node #u#.  In the worst
case, this is equal to the height of the #BinarySearchTree#.

\begin{figure}
  \begin{center}
    \begin{tabular}{cc}
    \includegraphics{figs/bst-example-4} &
    \includegraphics{figs/bst-example-5} 
    \end{tabular}
  \end{center}
  \caption{Inserting the value $8.5$ into a binary search tree.}
  \figlabel{bst-insert}
\end{figure}


\subsection{Deleting}

Deleting a value stored in a node, #u#, of a #BinarySearchTree# is a
little more difficult.  If #u# is a leaf, then we can just detach #u#
from its parent.  Even better: If #u# has only one child, then we can
splice #u# from the tree by having #u.parent# adopt #u#'s child:
\codeimport{ods/BinarySearchTree.splice(u)}

\begin{figure}
  \begin{center}
    \includegraphics{figs/bst-splice}
  \end{center}
  \caption{Deleting a leaf ($6$) or a node with only one child ($9$) is easy.}
  \figlabel{bst-splice}
\end{figure}

Things get tricky, though, when #u# has two children.  In this case,
the simplest thing to do is to find a node, #w#, that has less than
two children such that we can replace #u.x# with #w.x#.  To maintain
the binary search tree property, the value #w.x# should be close to the
value of #u.x#.  For example, picking #w# such that #w.x# is the smallest
value greater than #u.x# will do.  Finding the node #w# is easy; it is
the smallest value in the subtree rooted at #u.right#.  This node can
be easily removed because it has no left child.  (See \figref{bst-remove})
\codeimport{ods/BinarySearchTree.remove(u)}

\begin{figure}
  \begin{center}
    \begin{tabular}{cc}
    \includegraphics{figs/bst-delete-1}
    \includegraphics{figs/bst-delete-2}
    \end{tabular}
  \end{center}
  \caption{Deleting a value ($11$) from a node, #u#, with two children is done by replacing #u#'s value with the smallest value in the right subtree of #u#.}
  \figlabel{bst-remove}
\end{figure}

\subsection{Summary}

The #find(x)#, #add(x)#, and #remove(x)# operations in a
#BinarySearchTree# each involve following a path from the root of the
tree to some node in the tree. Without knowing more about the shape of
the tree it is difficult to say much about the length of this path,
except that it is less than #n#, the number of nodes in the tree.
The following (unimpressive) theorem summarizes the performance of the
#BinarySearchTree# data structure:

\begin{thm}\thmlabel{bst}
  A #BinarySearchTree# implements the #SSet# interface. A
  #BinarySearchTree# supports the operations #add(x)#, #remove(x)#,
  and #find(x)# in $O(#n#)$ time per operation.
\end{thm}

\thmref{bst} compares poorly with \thmref{skiplist}, which shows
that the #SkiplistSSet# structure can implement the #SSet# interface
with $O(\log #n#)$ expected time per operation.  The problem with the
#BinarySearchTree# structure is that it can become \emph{unbalanced}.
Instead of looking like the tree in \figref{bst} it can look like a long
chain of #n# nodes, all but the last having exactly one child.

There are a number of ways of avoiding unbalanced binary search
trees, all of which lead to data structures that have $O(\log
#n#)$ time operations. In \chapref{rbs} we show how $O(\log #n#)$
\emph{expected} time operations can be achieved with randomization.
In \chapref{scapegoat} we show how $O(\log #n#)$ \emph{amortized}
time operations can be achieved with partial rebuilding operations.
In \chapref{redblack} we show how $O(\log #n#)$ \emph{worst-case}
time operations can be achieved by simulating a tree that is not binary:
a tree in which nodes can have up to four children.

\section{Discussion and Exercises}

Binary trees have been used to model relationships for literally thousands
of years.  One reason for this is that binary trees naturally model
(pedigree) family trees.  These are the family trees in which the root is
a person, the left and right children are the person's parents, and so
on, recursively.  In more recent centuries binary trees have also been
used to model species-trees in biology, where the leaves of the tree
represent extant species and the internal nodes of the tree represent
\emph{speciation events} in which two populations of a single species
evolve into two separate species.

Binary search trees appear to have been discovered independently by
several groups in the 1950s \cite[Section~6.2.2]{k97v3}.  Further
references to specific kinds of binary search trees are provided in
subsequent chapters.

\begin{exc}
 Write a non-recursive variant of the #size2()# method, #size(u)#,
 that computes the size of the subtree rooted at node #u#.
\end{exc}

\begin{exc}
  Write a non-recursive method, #height2(u)#, that computes the height
 of node #u# in a  binary search tree.
\end{exc}

\begin{exc}
  A \emph{pre-order} traversal of a binary tree is a traversal that
  visits each node, #u#, before any of its children.
  An \emph{in-order} traversal visits #u# after visiting all the nodes
  in #u#'s left subtree but before visiting any of the nodes in #u#'s
  right subtree.  A \emph{post-order} traversal visits #u# only after
  visiting all other nodes in #u#'s subtree.

  Write non-recursive functions #nextPreOrder(u)#, #nextInOrder(u)#, and
  #nextPostOrder(u)# that return the node that follows #u# in a pre-order,
  in-order, or post-order traversal, respectively.
\end{exc}

\begin{exc}
  Describe a sequence of #n# operations on an initially empty
 #BinarySearchTree# that results in a tree of height $#n#-1$.
\end{exc}

\begin{exc}
  Design and implement a version of #BinarySearchTree# in which each node,
  #u#, maintains values #u.size# (the size of the subtree rooted at #u#),
  #u.depth# (the depth of #u#), and #u.height# (the height of the subtree
  rooted at #u#).  

  These values should be maintained, even during the #add(x)# and
  #remove(x)# operations, but this should not increase the cost of these
  operations by more than a constant factor.
\end{exc}
